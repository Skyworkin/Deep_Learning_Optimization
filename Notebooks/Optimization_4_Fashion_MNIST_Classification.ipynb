{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Optimize_Fashion_MNIST_Classification.ipynb","provenance":[{"file_id":"https://github.com/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb","timestamp":1582030194442}],"collapsed_sections":["v8A3NYh4q53g","LbCigZtNZZgl","tWORMSC8FDR4","Zx-Ee6LHZZgt","CFlNHktHBtru","HhalcO03ZZg3","FhxJ5dinZZg8","DtOvh3YVZZg_","e-MGLwZQy05d","9RTRkan4yq5H","oJv7XEk10bOv"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"r2NPAI4jZZgi","colab_type":"text"},"source":["# Classify Fashion-MNIST"]},{"cell_type":"markdown","metadata":{"id":"Ixyte299ZZgk","colab_type":"text"},"source":["## Notebook Overview\n","\n","<br> **Notebook is based on**: https://github.com/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb\n","\n","** Notable change: Uses tensorflow 2\n","\n","The [fashion_mnist](https://github.com/zalandoresearch/fashion-mnist) data: \n","60,000 train and 10,000 test data with 10 categories. Each gray-scale image is 28x28.\n","\n","<br> **Label**\t**Description**\n","<br> 0 T-shirt/top\n","<br> 1 Trouser\n","<br> 2 Pullover\n","<br> 3 Dress\n","<br> 4 Coat\n","<br> 5 Sandal\n","<br> 6 Shirt\n","<br> 7 Sneaker\n","<br> 8 Bag\n","<br> 9 Ankle boot\n","\n","Each gray-scale image is 28x28"]},{"cell_type":"markdown","metadata":{"id":"v8A3NYh4q53g","colab_type":"text"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"d44TznbgZZgm","colab_type":"code","colab":{}},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","tf.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LbCigZtNZZgl","colab_type":"text"},"source":["## Download fashion_mnist dataset\n","First let's install TensorFlow version 1.8.0 and import Tensorflow. Then we download fashion-mnist which is one of the Keras datasets. "]},{"cell_type":"code","metadata":{"id":"C534IT3rqr-k","colab_type":"code","colab":{}},"source":["\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Load the fashion-mnist pre-shuffled train data and test data\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tWORMSC8FDR4","colab_type":"text"},"source":["## Plot sample"]},{"cell_type":"code","metadata":{"id":"aFe4wHGRFKle","colab_type":"code","colab":{}},"source":["# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n","print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n","\n","# Print the number of training and test datasets\n","print(x_train.shape[0], 'train set')\n","print(x_test.shape[0], 'test set')\n","\n","# Define the text labels\n","fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n","                        \"Trouser\",      # index 1\n","                        \"Pullover\",     # index 2 \n","                        \"Dress\",        # index 3 \n","                        \"Coat\",         # index 4\n","                        \"Sandal\",       # index 5\n","                        \"Shirt\",        # index 6 \n","                        \"Sneaker\",      # index 7 \n","                        \"Bag\",          # index 8 \n","                        \"Ankle boot\"]   # index 9\n","\n","# Image index, you can pick any number between 0 and 59,999\n","img_index = 5\n","# y_train contains the lables, ranging from 0 to 9\n","label_index = y_train[img_index]\n","# Print the label, for example 2 Pullover\n","print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n","# # Show one of the images from the training dataset\n","plt.imshow(x_train[img_index])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zx-Ee6LHZZgt","colab_type":"text"},"source":["## Normalization\n"]},{"cell_type":"code","metadata":{"id":"XNh5NIckZZgu","colab_type":"code","colab":{}},"source":["x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMSg53fiZZgx","colab_type":"code","colab":{}},"source":["print(\"Number of train data - \" + str(len(x_train)))\n","print(\"Number of test data - \" + str(len(x_test)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CFlNHktHBtru","colab_type":"text"},"source":["## Split data into train/validation/test data sets\n","\n","\n","*   Training data - used for training the model\n","*   Validation data - used for tuning the hyperparameters and evaluate the models\n","*   Test data - used to test the model after the model has gone through initial vetting by the validation set.\n","\n"]},{"cell_type":"code","metadata":{"id":"1ShU787gZZg0","colab_type":"code","colab":{}},"source":["# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n","(x_train, x_valid) = x_train[5000:], x_train[:5000] \n","(y_train, y_valid) = y_train[5000:], y_train[:5000]\n","\n","# Reshape input data from (28, 28) to (28, 28, 1)\n","w, h = 28, 28\n","x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n","x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n","x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n","\n","# One-hot encode the labels\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","\n","# Print training set shape\n","print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n","\n","# Print the number of training, validation, and test datasets\n","print(x_train.shape[0], 'train set')\n","print(x_valid.shape[0], 'validation set')\n","print(x_test.shape[0], 'test set')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HhalcO03ZZg3","colab_type":"text"},"source":["## Create the model architecture\n","\n","There are two APIs for defining a model in Keras:\n","1. [Sequential model API](https://keras.io/models/sequential/)\n","2. [Functional API](https://keras.io/models/model/)\n","\n","In this notebook we are using the Sequential model API. \n","If you are interested in a tutorial using the Functional API, checkout Sara Robinson's blog [Predicting the price of wine with the Keras Functional API and TensorFlow](https://medium.com/tensorflow/predicting-the-price-of-wine-with-the-keras-functional-api-and-tensorflow-a95d1c2c1b03).\n","\n","In defining the model we will be using some of these Keras APIs:\n","*   Conv2D() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D/) - create a convolutional layer \n","*   Pooling() [link text](https://keras.io/layers/pooling/) - create a pooling layer \n","*   Dropout() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) - apply drop out "]},{"cell_type":"code","metadata":{"id":"jQQ-QlDeGInj","colab_type":"code","colab":{}},"source":["# for RAdam\n","!pip install -q tensorflow_addons"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V5OnXztsvBIM","colab_type":"code","colab":{}},"source":["import tensorflow_addons as tfa"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgTZ47SsZZg4","colab_type":"code","colab":{}},"source":["#tf.random.set_seed(42)\n","\n","model = tf.keras.Sequential()\n","\n","# Must define the input shape in the first layer of the neural network\n","\n","model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n","#model.add(tf.keras.layers.Dense(784, activation='relu',input_shape=(28,28,1)))\n","#model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, activation='relu')) \n","model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n","#model.add(tf.keras.layers.Dropout(0.3))\n","\n","model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n","#model.add(tf.keras.layers.Dropout(0.3))\n","\n","model.add(tf.keras.layers.Flatten())\n","#model.add(tf.keras.layers.Dense(256, activation='relu'))\n","model.add(tf.keras.layers.Dense(256, activation='relu'))\n","#model.add(tf.keras.layers.Dense(256, activation='relu'))\n","#model.add(tf.keras.layers.Dropout(0.5))\n","model.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","# Take a look at the model summary\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FhxJ5dinZZg8","colab_type":"text"},"source":["## Compile the model\n","Configure the learning process with compile() API before training the model. It receives three arguments:\n","\n","*   An optimizer \n","*   A loss function \n","*   A list of metrics \n"]},{"cell_type":"code","metadata":{"id":"CQUlOa8cZZg9","colab_type":"code","colab":{}},"source":["#tf.random.set_seed(1234)\n","#np.random.seed(1234)\n","\n","sgd = tf.keras.optimizers.SGD(learning_rate=1e-7)\n","momentum_with_nesterov = tf.keras.optimizers.SGD(momentum=0.95,nesterov=True)\n","adam = tf.keras.optimizers.Adam()\n","radam = tfa.optimizers.RectifiedAdam()\n","ranger = tfa.optimizers.Lookahead(radam) # Can be used with the other optimizers as well\n","\n","model.compile(loss='categorical_crossentropy',\n","             #optimizer=ranger,\n","             #optimizer=radam,\n","             optimizer=adam,\n","             #optimizer=momentum_with_nesterov,\n","             #optimizer=sgd,\n","             metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DtOvh3YVZZg_","colab_type":"text"},"source":["## Train the model\n","\n","Now let's train the model using the fit() API.\n","\n","The [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) API allows to save the model after every epoch. Set \"save_best_only = True\" to save iff validation accuracy improves.\n","\n","**Attention** - The ModelCheckpoint API allows us to continue the training from a given state - if you want to start over you might have to recreate the model architecture"]},{"cell_type":"code","metadata":{"id":"ZTmapAttZZhA","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","\n","checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n","model.fit(x_test,\n","         y_test,\n","         batch_size=64,\n","         epochs=10,\n","         validation_data=(x_valid, y_valid),\n","         callbacks=[checkpointer])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e-MGLwZQy05d","colab_type":"text"},"source":["## Load Model with best validation accuracy"]},{"cell_type":"code","metadata":{"id":"UD1tecxUZZhE","colab_type":"code","colab":{}},"source":["# Load the saved weights with best validation accuracy\n","model.load_weights('model.weights.best.hdf5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9RTRkan4yq5H","colab_type":"text"},"source":["## Test Accuracy"]},{"cell_type":"code","metadata":{"id":"VZtqBqFFy62R","colab_type":"code","colab":{}},"source":["# Evaluate model on test set\n","score = model.evaluate(x_test, y_test, verbose=0)\n","\n","# Print test accuracy\n","print('\\n', 'Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oJv7XEk10bOv","colab_type":"text"},"source":["## Visualize predictions\n","We get the predictions applying the trained model to the test data.\n","We then print out 15 images from the test set, the titles show predicted labels (versus the ground truth labels).\n","If the prediction matches the true label, the title is shown in green; otherwise it's displayed in red."]},{"cell_type":"code","metadata":{"id":"QwNmlfIC0YxM","colab_type":"code","colab":{}},"source":["y_hat = model.predict(x_test)\n","\n","# Plot a random sample of 10 test images, their predicted labels and ground truth\n","figure = plt.figure(figsize=(20, 8))\n","np.random.seed(42)\n","for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n","    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n","    # Display each image\n","    ax.imshow(np.squeeze(x_test[index]))\n","    predict_index = np.argmax(y_hat[index])\n","    true_index = np.argmax(y_test[index])\n","    # Set the title for each image\n","    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n","                                  fashion_mnist_labels[true_index]),\n","                                  color=(\"green\" if predict_index == true_index else \"red\"))"],"execution_count":0,"outputs":[]}]}